---
title: "Causal Inference Examples"
author: "Ryan_Gan"
date: "January 19, 2017"
output: html_document
---

## Introduction

This markdown file was created to help me further understand key concepts in causal inference statistics to help in our causal inference papers. Recently (December 2016), Oleg Sofrygin created a pretty awesom package called 'simcausal'. Mark van der Laan (creator of the super learner package), and Romain Neugebauer are also authors on this package. This package makes creation of direceted acyclic graphs (DAGs) in a structural equations modeling (SEM) framework easy. Furthermore, it makes the simulation of data that adhere to your desired DAG very easy as well. I think this could eventually be useful for other people, but I'll need to be better about describing DAG theory.

```{r load libraries}
library(simcausal) # simulation of causal structure data
library(broom) # for easy conversion of model results to dataframes
library(tidyverse) # data wrangling
```

## Simple Relationship

Let's start simple. Say you want to determine the effect of binary exposure "X" on binary outcome "Y". Let's create a DAG to show X affecting Y. In DAG terminology, the X and Y variables are sometimes called "nodes". The arrows connecting nodes are called "edges". 
The simcausal package even easily creates the DAG plot. I'm not familiar on all the plot options yet, so my DAGs may look pretty basic.

```{r x y dag}
# using 'simcausal' package, first create an empty DAG using the appropriately
# named DAG.empty function.
d.1 <- DAG.empty()

# now using a SEM framework of notation, we define the relationship between 
# each node of the DAG
d.1 <- d.1 +
  # create node X
  # 'distr' defines the distribution we want to use. In this case, I want
  # a binary categorical variable with an equal distribution of 50% in the 
  # simulated data
  node("X", distr = "rcat.b1", prob = c(0.5, 0.5)) +  
  # create node Y
  # we use a Bernoulli distribution, which is equivalent to a binomial 
  # distribution when all X are independent, identically distribution (iid)
  # and random variables
  node("Y", distr = "rbern",
  # define the relationship between X and Y
  # lets say the baseline probability/risk for Y for unexposed X is ~.50
  # and the odds ratio (relative associatoin) for Y | X = exposed is 
  # roughly 2 times greater
  prob = plogis(0 + 0.69 * X))

# we now need to set the DAG we just created
d.1 <- set.DAG(d.1)

# now that this DAG is set, it's easy to plot
plotDAG(d.1, xjitter = 0, yjitter = 0,
        edge_attrs = list(width = 2, arrow.width = 2, arrow.size = 0.5),
        vertex_attrs = list(size = 24, label.cex = 0.8))

```

The DAG above shows a relationship between X and Y. In more specific "causal inference"" terminology we would say that "X affects Y".

We can also easily simulate data to analyze with the "simcausal" package. 

```{r create data}
# create simulated dataframe of DAG
# DAG option is the dag you want to simulate
# n is the sample size we want to simulate. Here we want 10,000 observatoins
# rndseed is the randomseed. Doesn't matter what number you define, but if you want
# to reproduce your data exactly, use the same seed
d.1_df <-  sim(DAG = d.1, n = 10000, rndseed = 321)

```

Of course we can always calculate our simple 2x2 sample by hand.

```{r hand cals}
# find cell vals
xtabs(~X+Y, d.1_df)
# find odds ratio
odds_ratio <- (3997/1019)/(3333/1651) 
se <- sqrt((1/3997) + (1/1019) + (1/3333) + (1/1651))
lower_bound <- log(odds_ratio) - (se*1.96)
upper_bound <- log(odds_ratio) + (se*1.96)

names <- c("OR", "95_lower", "95_upper")
vals <- round(exp(c(log(odds_ratio), lower_bound, upper_bound)), 2)
or_df <- rbind(names, vals)
or_df

# find risk difference
risk_diff <- (3997/(3997+1019)) - (3333/(3333+1651))
# fill in standard error latter

```

Let's run a logistic regression on our simulated data to see if it has the properties we expect. I like to use the 'broom' (David Robinson) and 'tidyverse' (Hadley Wickham) to make data manipulation and output easier to read.

```{r xy mod}


mod1 <- tidy(glm(Y~X, data = d.1_df, family="binomial"(link="logit")))
# model fits how we defined it
mod1

# calcualte 95%CI around estimate for X
estimate <- mod1[2,2]
lower_bound <- mod1[2,2] - (1.96*mod1[2,3])
upper_bound <- mod1[2,2] + (1.96*mod1[2,3])
# Odds ratio for the effect of X on Y
names <- c("OR", "95_lower", "95_upper")
vals <- round(exp(c(estimate, lower_bound, upper_bound)), 2)
or_df <- rbind(names, vals)
or_df

```

Our simulated data fits our DAG. We may interpret the odds ratio in causal inference language as follows:
Exposure to X increased the odds of Y by ~2 times. This is consistent with our causal hypothesis of X affecting Y. 

We could also estimate the risk difference in these data using a generalized linear regression model using binomial distribution with identity link.

```{r xy risk diff}

risk_diff_mod <- tidy(glm(Y ~ X, data = d.1_df,family = "binomial"(link="identity")))
risk_diff_mod

```

Both our generalized linear regression models match what we would calculate by hand.

It's also important to note we could easily hypothesize that Y affects X. And those data may have the exact same relationship with each other.L et's draw a DAG and simulate.

```{r yx dag}

dag2 <- DAG.empty()

# now using a SEM framework of notation, we define the relationship between 
# each node of the DAG
dag2 <- dag2 +
  node("Y", distr = "rcat.b1", prob = c(0.5, 0.5)) +  
  node("X", distr = "rbern",
  prob = plogis(0 + 0.69 * Y))

# we now need to set the DAG we just created
dag2 <- set.DAG(dag2)

# now that this DAG is set, it's easy to plot
plotDAG(dag2, xjitter = 0, yjitter = 0,
        edge_attrs = list(width = 2, arrow.width = 2, arrow.size = 0.5),
        vertex_attrs = list(size = 24, label.cex = 0.8))

df_2 <- sim(DAG = dag2, n = 10000, rndseed = 321)

# odds ratio 
or_mod <- tidy(glm(X ~ Y, data = df_2, family = "binomial"(link="logit")))
or_mod
# calcualte 95%CI around estimate for X
estimate <- or_mod[2,2]
lower_bound <- or_mod[2,2] - (1.96*or_mod[2,3])
upper_bound <- or_mod[2,2] + (1.96*or_mod[2,3])
# Odds ratio for the effect of X on Y
names <- c("OR", "95_lower", "95_upper")
vals <- round(exp(c(estimate, lower_bound, upper_bound)), 2)
or_df <- rbind(names, vals)
or_df

# risk diff
risk_diff_mod <- tidy(glm(X ~ Y, data = df_2,family = "binomial"(link="identity")))
risk_diff_mod
```


Notice we get the exact same values in this newly simulated dataframe when we use the same parameters as before. The important lesson here is that statistical models make no distinction of direction of associaiton, and it's up to us as the modeler to build the best possible model we can that is consistent with our hypothesis. 

As Pearl states, common words to express statistical relationships such as correlations or associations make no distinction of the direction of association. In many cases, we may want to use these terms. For exmaple, in the case of cross-sectional analyses. However, since we are talking about 'causal inference', it's important to note that we may say 'X affects/causes Y', but statistically, 'Y affects/causes X' could be just as likely given the data. This is where I think DAGs really help. They help visually represent our assumptions about our statistical model, given how our data were collected, our knowledge of the topic, etc. 

## Confounding Bias

One area I believe the area of "causal inference" has really helped epidemiologic reasearch is by simplifying the biases that may be present in data to really just two major biases: confounding bias, and collider bias (selection bias). In a general sense confounding happens when a third variable/factor (which we'll call C for now) distorts the relationship between our X and Y association. I think the most common definition of confounding used in epidemiology courses today probably goes something like this:

*Confounding between X and Y occurs when there is an association between C and X, and there is an association between C and Y.* 
It may also include this extra piece: *And C is not on the causal pathway between X and Y.*

However, "causal inference" has a more specific definition of confounding:
*Confounding between X and Y occurs when C affects X and C affects Y.*

The DAG would look like this.

```{r confounding dag}

con_dag <- DAG.empty()

# now using a SEM framework of notation, we define the relationship between 
# each node of the DAG
con_dag <- con_dag +
  node("C", distr = "rcat.b1", prob = c(0.5, 0.5)) +
  node("X", distr = "rbern", prob = plogis(0 + 1.5 * C)) +
  node("Y", distr = "rbern",
  prob = plogis(0 + 1.5 * C))

# we now need to set the DAG we just created
con_dag <- set.DAG(con_dag)

# now that this DAG is set, it's easy to plot
plotDAG(con_dag, xjitter = 0, yjitter = 0,
        edge_attrs = list(width = 2, arrow.width = 2, arrow.size = 0.5),
        vertex_attrs = list(size = 24, label.cex = 0.8))
```


Here is shows the X and Y are d-seperated, conditioned on C. We can see that in our model, where when we adjust for C, we would conclude there is no associatoin between X and Y.

```{r confound control}

c_df <- sim(DAG = con_dag, n = 10000, rndseed = 321)

# unadjusted model
crude_mod <- tidy(glm(Y ~ X, data = c_df, family = "binomial"(link="logit")))

# calcualte 95%CI around estimate for X
estimate <- crude_mod[2,2]
lower_bound <- crude_mod[2,2] - (1.96*crude_mod[2,3])
upper_bound <- crude_mod[2,2] + (1.96*crude_mod[2,3])
# Odds ratio for the effect of X on Y
names <- c("OR", "95_lower", "95_upper")
crude_vals <- round(exp(c(estimate, lower_bound, upper_bound)), 2)
or_df <- rbind(names, crude_vals)
or_df

# adjusted odds ratio 
adj_mod <- tidy(glm(Y ~ X + C, data = c_df, family = "binomial"(link="logit")))
adj_mod
# calcualte 95%CI around estimate for X
estimate <- adj_mod[2,2]
lower_bound <- adj_mod[2,2] - (1.96*adj_mod[2,3])
upper_bound <- adj_mod[2,2] + (1.96*adj_mod[2,3])
# Odds ratio for the effect of X on Y
names <- c("OR", "95_lower", "95_upper")
adj_vals <- round(exp(c(estimate, lower_bound, upper_bound)), 2)
or_df <- rbind(names, adj_vals)
or_df


# risk diff
risk_diff_mod <- tidy(glm(Y ~ X + C, data = c_df,family = "binomial"(link="identity")))
risk_diff_mod

```

## Collider Bias

The second type of bias that occur within your data is collider bias. For epidemiologists, selection bias is a type of collider bias. A definition of collider bias would be:

*Collider bias occurs when X affects C, and where Y affects C.*

The using the same variables where X is our exposure, Y is our outcome, and C is some third variable that acts as a collider, the DAG would look like this.


```{r collider dag}

col_dag <- DAG.empty()

# now using a SEM framework of notation, we define the relationship between 
# each node of the DAG
col_dag <- col_dag +
  node("X", distr = "rcat.b1", prob = c(0.5, 0.5)) +
  node("Y", distr = "rbern", prob = c(0.6, 0.4)) +
  node("C", distr = "rbern",
  prob = plogis(0 + 1.0 * Y + -0.5 *X))

# we now need to set the DAG we just created
col_dag <- set.DAG(col_dag)

# now that this DAG is set, it's easy to plot
plotDAG(col_dag, xjitter = 0, yjitter = 0,
        edge_attrs = list(width = 2, arrow.width = 2, arrow.size = 0.5),
        vertex_attrs = list(size = 24, label.cex = 0.8))
```

In this DAG, X and Y are d-seperated, unless we open up the path through collider C. Notice that the arrows leave from both X and Y *into* C. Thus C acts as a collider, opening up the path between X and Y if adjusted for.

```{r true model}
# make collider dataframe
col_df <- sim(DAG = col_dag, n = 10000, rndseed = 321) %>% 
  # need to convert categorical Y to 1 or 0 to use with logistic
  mutate(Y = ifelse(Y == 1, 1, 0))

# true odds ratio 
true_mod <- tidy(glm(Y ~ X, data = col_df, family = "binomial"(link="logit")))
true_mod
# calcualte 95%CI around estimate for X
estimate <- true_mod[2,2]
lower_bound <- true_mod[2,2] - (1.96*true_mod[2,3])
upper_bound <- true_mod[2,2] + (1.96*true_mod[2,3])
# Odds ratio for the effect of X on Y
names <- c("OR", "95_lower", "95_upper")
true_vals <- round(exp(c(estimate, lower_bound, upper_bound)), 2)
or_df <- rbind(names, true_vals)
or_df

```

In this case, our 'true' estimates (based on our DAG) show no association between X and Y. Which is also what our DAG shows, as X and Y are d-seperated.

However, what if we mistakenly think C is actually a confounder and decide to adjust for it in our model?

```{r collider model}

# collider odds ratio 
col_mod <- tidy(glm(Y ~ X + C, data = col_df, family = "binomial"(link="logit")))
col_mod
# calcualte 95%CI around estimate for X
estimate <- col_mod[2,2]
lower_bound <- col_mod[2,2] - (1.96*col_mod[2,3])
upper_bound <- col_mod[2,2] + (1.96*col_mod[2,3])
# Odds ratio for the effect of X on Y
names <- c("OR", "95_lower", "95_upper")
collider_vals <- round(exp(c(estimate, lower_bound, upper_bound)), 2)
or_df <- rbind(names, collider_vals)
or_df

```

If we adjust for C in this case, we have introduced collider bias. Our estimate is now biased as well. The lesson is that if the arrows go in to a variable, you may not want to adjust for such a variable. This could include mediating variables, which is a special case of collider bias. If the arrows leave the variable, then it should be adjusted for to control for confounding bias.

*Important reminder is that real data is messy, and these causal structures (DAGs) within data are not always apparent. Its good practice to draw multiple DAGs, test each node arch node in the DAG, and decide which DAG structure is more likely. This is the 'art' of model building, much like backwards or forwards selection, or some other model selection strategy. I prefer DAGs because it makes my assumptions about the questions I'm trying to ask explicit.*

Now what if we have some unmeasured variable or we introduce collider bias on accident? This is where *potential outcomes framework*, a.k.a *counter factual estimation*. There are a couple different methods used commonly in epidemiologic research that fall in to this category: g-computation, a.k.a simple substitution and inverse probability weighting (IPTW). But the general idea behind both these methods is that we have a binary exposure variable, X. Our study subjects are observed to be either exposed (X = 1), or unexposed (X = 0). Each subject can obviously only have one realized value for exposure. That is a subject with exposure X = 1, cannot take on X = 0. However, we often like to think and talk in counterfactual terms. That is, would subjects with exposure X = 1 still have developed disease Y had they, counter to the fact, had exposure X = 0. This is where some old epidemiologic concepts come in handy. Identifiability and exchangability (See Greenland and Robins 1990s?).  



