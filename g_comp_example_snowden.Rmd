---
title: "Reproducing Results in Snowden G-Comp Paper"
author: "Ryan_Gan"
date: "April 18, 2017"
output: html_document
---

Using code from Snowden paper to try out MSM models and maybe test out SuperLearner and Target Maximum Likelihood packages.

```{r libraries}
library(tidyverse)
library(broom)
```

Simulating data as defined in the paper. Paper goes in to various model fits and how MSM estimates. First step of a marginal structral model is to define the I'm just going to go to example 4 where the appropriate interaction between A and W2 is specified.

```{r simulate data}
# sample size
n <- 300
set.seed(285)
simdata <- data.frame(W1 = rbinom(n, 1, 0.4), W2 = rbinom(n, 1, 0.5))
# add simulated data of A
simdata <- transform(simdata, A = rbinom(n, 1, (0.5+0.2*W1-0.3*W2)))
# add simulated data of Y
simdata <- transform(simdata, Y = rnorm(n, (3-0.5*A+W1+0.3*A*W2), 0.4))

# create counterfactual datasets 
# A = 0
simdata_a0 <- transform(simdata, A = 0)
# A = 1
simdata_a1 <- transform(simdata, A = 1)
```

## G-computation (simple substitution)

Applying simple substitution method (g-computation). 

*Step 1. Estimation of the conditional mean outcome Eo(Y|A,W,A:W2)*

```{r gcomp step 1}
# Step 1: Define Q formula
reg_mod <- glm(Y~A+W1+A:W2, data = simdata, family = gaussian)
summary(reg_mod)
```

*Step 2. Obtaining predicted outcomes under everyone exposed and no one exposured*

Next we need to update the predicted FEV1 values where everyone is exposed and no one is exposed.

```{r gcomp step 2}
# Step 2: Updated predicted value
# values of everyone exposed
pr_fev_a1 <- predict(reg_mod, newdata = simdata_a1)
# values of no one exposed
pr_fev_a0 <- predict(reg_mod, newdata = simdata_a0)
```

*Step 3. Estimate the statistical parameter by substituting the predicted mean outcomes under everyone exposed and no one exposed*

```{r gcomp step 3}
mean(pr_fev_a1)
mean(pr_fev_a0)
# MSM value
fev_est <- mean(pr_fev_a1) - mean(pr_fev_a0)
fev_est
```

In order to get estimates of uncertainty around our MSM estimate ( 95% confidence invervals), we need to bootstrap.

First I create a general function that calculates g-comp with a couple user-defined inputs.

```{r gcomp function and bootstrap}
# might be able to cut out y element of formula and add it to q_mod

# create a g-comp function
g_comp_func <- function(data, y, a, q_mod, mod_family, estimate){
  # create a = 1 and a = 0 dataframes ----
  a1_df <- a0_df <- data
  a1_df[, a] <- 1
  a0_df[, a] <- 0
  # run q-formula ----
  # may consider moving model specification outside of function
    model <- glm(as.formula(paste(y, q_mod, sep = "~")), data = data, family = mod_family)
     # calculate mean expected in a1 and a0
      pr_a1 <- mean(predict(model, newdata = a1_df, type = "response")) 
      pr_a0 <- mean(predict(model, newdata = a0_df, type = "response"))

  # calculate desired estimates "diff", "ratio", "both" ----
    # calculate difference a1 to a0
    if(estimate == "diff"){
      msm_diff <- pr_a1 - pr_a0
      msm_val <- msm_diff
    }
    # calculate ratio of a1/a0
    if(estimate == "ratio"){
      msm_ratio <- pr_a1/pr_a0 
      msm_val <- msm_ratio
    } 
    # output (i want to figure out how to assign it a name)
      return(msm_val)
      
    # calculate both ratio and difference
    # if(estimate == "both"){
    #   msm_diff <- pr_a1 - pr_a0
    #   msm_ratio <- pr_a1/pr_a0
    #   msm_val <- rbind(c("Risk Difference", msm_diff),
    #                    c("Risk Ratio", msm_ratio))
    # }
  
} # end function
```

Testing function to see if it produces the same results.

```{r gcomp func test}
meow <- g_comp_func(data = simdata, y = "Y", a = "A", q_mod = "A+W1+A:W2",
            mod_family = "gaussian", estimate = "diff")
meow
```

Function works. Now we can feed it through broom's bootstrap function and calculation 95%CIs via percentile method.

```{r gcomp boot}
# percentile method with broom
set.seed(321)
boot_msm <- simdata %>% bootstrap(1000) %>% 
  do(tidy(g_comp_func(data = ., y = "Y", a = "A", q_mod = "A+W1+A:W2",
            mod_family = "gaussian", estimate = "diff")))

# create empty matrix
estimates <- matrix(nrow = 1, ncol = 4, byrow = T)
colnames(estimates) <- c("msm_estimate", "boot_median", "lower_95", "upper_95")

# fill matrix 
estimates[,1] <- round(meow,3)
estimates[,2] <- round(quantile(boot_msm$x, 0.5),3)
estimates[,3] <- round(quantile(boot_msm$x, 0.025),3)
estimates[,4] <- round(quantile(boot_msm$x, 0.975),3)

# convert matrix to dataframe
est_df <- data.frame(estimates)

knitr::kable(est_df, caption = paste0("MSM estimates with bootstrapped 95%CI"))
```

## Inverse probability of treatment weight (IPTW)

This method is similar to g-computation, but differs slightly in that confounding can be thought of as a problem of bias sampling where certain exposure-covariate subgroups are over or under represted compared to an RCT. IPTW up-weights under-represted subjects from exposure-covariate strata. Sounds like Bayesian nonsense.

*Step 1. Estimate the propensity score Pr(A|W)*

I'm actually interested to see how this will work since Snowden et al put an interesting interaction in. Maybe this was the point of their paper? Need to read it again on why they used g-comp over IPTW.

```{r iptw step 1}
prop_mod <- glm(A ~ W1 + W2, family = "binomial", data = simdata)
summary(prop_mod)
```

*Step 2. Create weights*

Multi-step process of creating weights for the probability of being exposed. We also check for ETA violations here where, given the covariates W, probability of exposed or unexposed might be >.90.

```{r iptw step 2}
# vector of propensity exposed for each observation
prob_exposed <- predict(prop_mod, type = "response")
# vector of propensity not exposed
prob_unexposed <- 1 - prob_exposed 
# histogram to check for ETA violation
hist(prob_exposed)

# create weights
wt <- as.numeric(simdata$A == 1)/prob_exposed + 
  as.numeric(simdata$A == 0)/prob_unexposed

# checking to make sure we inverted probabilities correctly
head(data.frame(simdata$Y, simdata$A, 1/prob_exposed, 1/prob_unexposed, wt))
```

*Step 3. Estimate statistical parameter*

```{r iptw step 3}
iptw <- mean(as.numeric(simdata$A==1)*wt*simdata$Y) -
  mean(as.numeric(simdata$A==0)*wt*simdata$Y)

iptw
```